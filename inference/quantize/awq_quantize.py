#!/usr/bin/env python3
"""
AWQ é‡åŒ–è„šæœ¬

AWQ (Activation-aware Weight Quantization) æ˜¯ä¸€ç§åŸºäºæ¿€æ´»å€¼åˆ†å¸ƒçš„æƒé‡é‡åŒ–æ–¹æ³•ï¼Œ
èƒ½åœ¨ä¿æŒè¾ƒé«˜ç²¾åº¦çš„åŒæ—¶å°†æ¨¡å‹å‹ç¼©åˆ° 4-bitã€‚

ä¾èµ–ï¼š
    pip install autoawq transformers

ç”¨æ³•ï¼š
    # åŸºæœ¬ç”¨æ³•
    python awq_quantize.py --model_path /path/to/model --output_path /path/to/output

    # è‡ªå®šä¹‰å‚æ•°
    python awq_quantize.py \
        --model_path Qwen/Qwen2.5-7B-Instruct \
        --output_path ./qwen2.5-7b-awq \
        --bits 4 \
        --group_size 128 \
        --calib_samples 512
"""

from __future__ import annotations

import argparse
from pathlib import Path


def quantize_awq(
    model_path: str,
    output_path: str,
    bits: int = 4,
    group_size: int = 128,
    zero_point: bool = True,
    calib_data: str = "wikitext",
    calib_samples: int = 512,
    calib_seq_len: int = 512,
):
    """æ‰§è¡Œ AWQ é‡åŒ–"""

    try:
        from awq import AutoAWQForCausalLM
        from transformers import AutoTokenizer
    except ImportError as e:
        print(f"âŒ ç¼ºå°‘ä¾èµ–: {e}")
        print("   è¯·å®‰è£…: pip install autoawq transformers")
        return False

    print("=" * 60)
    print("AWQ é‡åŒ–é…ç½®")
    print("=" * 60)
    print(f"  æ¨¡å‹è·¯å¾„: {model_path}")
    print(f"  è¾“å‡ºè·¯å¾„: {output_path}")
    print(f"  é‡åŒ–ä½æ•°: {bits}")
    print(f"  åˆ†ç»„å¤§å°: {group_size}")
    print(f"  é›¶ç‚¹é‡åŒ–: {zero_point}")
    print(f"  æ ¡å‡†æ•°æ®: {calib_data}")
    print(f"  æ ¡å‡†æ ·æœ¬: {calib_samples}")
    print("=" * 60)

    # åŠ è½½æ¨¡å‹
    print("\nğŸ“¦ åŠ è½½æ¨¡å‹...")
    model = AutoAWQForCausalLM.from_pretrained(
        model_path,
        trust_remote_code=True,
        safetensors=True,
    )
    tokenizer = AutoTokenizer.from_pretrained(
        model_path,
        trust_remote_code=True,
    )

    # é‡åŒ–é…ç½®
    quant_config = {
        "zero_point": zero_point,
        "q_group_size": group_size,
        "w_bit": bits,
        "version": "GEMM",  # GEMM æˆ– GEMV
    }

    # æ‰§è¡Œé‡åŒ–
    print("\nğŸ”§ å¼€å§‹é‡åŒ–...")
    model.quantize(
        tokenizer,
        quant_config=quant_config,
        calib_data=calib_data,
        n_samples=calib_samples,
        seqlen=calib_seq_len,
    )

    # ä¿å­˜æ¨¡å‹
    print(f"\nğŸ’¾ ä¿å­˜æ¨¡å‹åˆ°: {output_path}")
    output_dir = Path(output_path)
    output_dir.mkdir(parents=True, exist_ok=True)

    model.save_quantized(str(output_dir))
    tokenizer.save_pretrained(str(output_dir))

    # è¾“å‡ºç»Ÿè®¡
    total_size = sum(f.stat().st_size for f in output_dir.glob("**/*") if f.is_file())
    print(f"\nâœ… é‡åŒ–å®Œæˆï¼")
    print(f"   è¾“å‡ºç›®å½•: {output_dir}")
    print(f"   æ€»å¤§å°: {total_size / 1024 / 1024 / 1024:.2f} GB")

    return True


def main():
    parser = argparse.ArgumentParser(
        description="AWQ é‡åŒ–å·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # åŸºæœ¬ç”¨æ³•
  python awq_quantize.py --model_path ./model --output_path ./model-awq

  # ä½¿ç”¨ HuggingFace æ¨¡å‹
  python awq_quantize.py --model_path Qwen/Qwen2.5-7B-Instruct --output_path ./qwen2.5-7b-awq

  # è‡ªå®šä¹‰é‡åŒ–å‚æ•°
  python awq_quantize.py --model_path ./model --output_path ./model-awq --bits 4 --group_size 64
        """
    )

    parser.add_argument(
        "--model_path",
        type=str,
        required=True,
        help="æ¨¡å‹è·¯å¾„ï¼ˆæœ¬åœ°è·¯å¾„æˆ– HuggingFace æ¨¡å‹åï¼‰"
    )
    parser.add_argument(
        "--output_path",
        type=str,
        required=True,
        help="è¾“å‡ºç›®å½•è·¯å¾„"
    )
    parser.add_argument(
        "--bits",
        type=int,
        default=4,
        choices=[4, 8],
        help="é‡åŒ–ä½æ•°ï¼ˆé»˜è®¤: 4ï¼‰"
    )
    parser.add_argument(
        "--group_size",
        type=int,
        default=128,
        help="é‡åŒ–åˆ†ç»„å¤§å°ï¼ˆé»˜è®¤: 128ï¼‰"
    )
    parser.add_argument(
        "--zero_point",
        action="store_true",
        default=True,
        help="å¯ç”¨é›¶ç‚¹é‡åŒ–ï¼ˆé»˜è®¤å¯ç”¨ï¼‰"
    )
    parser.add_argument(
        "--no_zero_point",
        action="store_true",
        help="ç¦ç”¨é›¶ç‚¹é‡åŒ–"
    )
    parser.add_argument(
        "--calib_data",
        type=str,
        default="wikitext",
        help="æ ¡å‡†æ•°æ®é›†ï¼ˆé»˜è®¤: wikitextï¼‰"
    )
    parser.add_argument(
        "--calib_samples",
        type=int,
        default=512,
        help="æ ¡å‡†æ ·æœ¬æ•°ï¼ˆé»˜è®¤: 512ï¼‰"
    )
    parser.add_argument(
        "--calib_seq_len",
        type=int,
        default=512,
        help="æ ¡å‡†åºåˆ—é•¿åº¦ï¼ˆé»˜è®¤: 512ï¼‰"
    )

    args = parser.parse_args()

    # å¤„ç† zero_point å‚æ•°ï¼š--no_zero_point ä¼˜å…ˆçº§é«˜äº --zero_point
    zero_point = not args.no_zero_point
    
    success = quantize_awq(
        model_path=args.model_path,
        output_path=args.output_path,
        bits=args.bits,
        group_size=args.group_size,
        zero_point=zero_point,
        calib_data=args.calib_data,
        calib_samples=args.calib_samples,
        calib_seq_len=args.calib_seq_len,
    )

    if not success:
        exit(1)


if __name__ == "__main__":
    main()
